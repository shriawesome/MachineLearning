{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'review', 'rating', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products=pd.read_csv('data_set/amazon_baby_subset.csv')\n",
    "products.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of ou...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>My daughter had her 1st baby over a year ago. ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lamaze Peekaboo, I Love You</td>\n",
       "      <td>One of baby's first and favorite books, and it...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SoftPlay Peek-A-Boo Where's Elmo A Children's ...</td>\n",
       "      <td>Very cute interactive book! My son loves this ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Beautiful book, I love it to record cherished ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hunnt&amp;reg; Falling Flowers and Birds Kids Nurs...</td>\n",
       "      <td>Try this out for a spring project !Easy ,fun a...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blessed By Pope Benedict XVI Divine Mercy Full...</td>\n",
       "      <td>very nice Divine Mercy Pendant of Jesus now on...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>We bought the pins as my 6 year old Autistic s...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cloth Diaper Pins Stainless Steel Traditional ...</td>\n",
       "      <td>It has been many years since we needed diaper ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumb...   \n",
       "1    Nature's Lullabies Second Year Sticker Calendar   \n",
       "2    Nature's Lullabies Second Year Sticker Calendar   \n",
       "3                        Lamaze Peekaboo, I Love You   \n",
       "4  SoftPlay Peek-A-Boo Where's Elmo A Children's ...   \n",
       "5                          Our Baby Girl Memory Book   \n",
       "6  Hunnt&reg; Falling Flowers and Birds Kids Nurs...   \n",
       "7  Blessed By Pope Benedict XVI Divine Mercy Full...   \n",
       "8  Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "9  Cloth Diaper Pins Stainless Steel Traditional ...   \n",
       "\n",
       "                                              review  rating  sentiment  \n",
       "0  All of my kids have cried non-stop when I trie...       5          1  \n",
       "1  We wanted to get something to keep track of ou...       5          1  \n",
       "2  My daughter had her 1st baby over a year ago. ...       5          1  \n",
       "3  One of baby's first and favorite books, and it...       4          1  \n",
       "4  Very cute interactive book! My son loves this ...       5          1  \n",
       "5  Beautiful book, I love it to record cherished ...       5          1  \n",
       "6  Try this out for a spring project !Easy ,fun a...       5          1  \n",
       "7  very nice Divine Mercy Pendant of Jesus now on...       5          1  \n",
       "8  We bought the pins as my 6 year old Autistic s...       4          1  \n",
       "9  It has been many years since we needed diaper ...       5          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "-1    26493\n",
       " 1    26579\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.groupby('sentiment').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply text cleaning on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading json file\n",
    "important_words=list(pd.read_json('data_set/important_words.json')[0].values)\n",
    "len(important_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "<br>\n",
    "Let us perform 2 simple data transformations:\n",
    "\n",
    "Remove punctuation<br>\n",
    "Compute word counts (only for important_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "products=products.fillna({'review':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(text.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['review_clean']=products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word]=products['review_clean'].apply(lambda s:s.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'review', 'rating', 'sentiment', 'review_clean', 'baby', 'one',\n",
       "       'great', 'love', 'use',\n",
       "       ...\n",
       "       'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won',\n",
       "       'tub', 'almost', 'either'],\n",
       "      dtype='object', length=198)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question. How many reviews contain the word perfect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products[products['perfect']!=0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(data_set,features,output):\n",
    "    data_set['constant']=1\n",
    "    features=['constant']+features\n",
    "    feature_matrix=np.array(data_set[features])\n",
    "    output_matrix=np.array(data_set[output])\n",
    "    return feature_matrix,output_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix,sentiment=get_numpy_data(products,important_words,'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question: How many features are there in the feature_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Conditional probability with link function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probability(feature_matrix,coefficients):\n",
    "    predictions=[]\n",
    "    score=np.dot(feature_matrix,coefficients)\n",
    "    for s in score:\n",
    "        p=1/(1+math.exp(-s))\n",
    "        predictions.append(p)\n",
    "    predictions=np.array(predictions)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial derivative wrt to coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors,feature):\n",
    "    derivative=np.dot(errors,feature)\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note :\n",
    " In the main lecture, our focus was on the likelihood. In the advanced optional video, however, we introduced a transformation of this likelihood---called the log-likelihood---that simplifies the derivation of the gradient and is more numerically stable. Due to its numerical stability, we will use the log-likelihood instead of the likelihood to assess the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix,sentiment,coefficients):\n",
    "    indicator=(sentiment==+1)\n",
    "    scores=np.dot(feature_matrix,coefficients)\n",
    "    lp=np.sum((indicator-1)*scores - np.log(1.+np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(feature_matrix,sentiment,initial_coefficients,step_size,max_iter):\n",
    "    coefficients=np.array(initial_coefficients)\n",
    "    for itr in range(max_iter):\n",
    "        predictions=predict_probability(feature_matrix,coefficients)\n",
    "        ## Compute indicator i.e. y_i=+1\n",
    "        indicator=(sentiment==+1)\n",
    "        errors=indicator - predictions\n",
    "        for j in range(len(coefficients)):\n",
    "            derivative=feature_derivative(errors,feature_matrix[:,j])\n",
    "            coefficients[j]+=step_size*derivative\n",
    "            \n",
    "        #Checking whether log likelihood is increasing\n",
    "        if itr<=15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) or  (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp=compute_log_likelihood(feature_matrix,sentiment,coefficients)\n",
    "            print('Iteration %d: log likelihood of observed labels = %.8f'%(itr,lp))\n",
    "        \n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_coefficients=np.zeros(194)\n",
    "step_size=1e-7\n",
    "max_iter=301"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: As each iteration of gradient ascent passes, does the log likelihood increase or decrease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: log likelihood of observed labels = -36780.91768478\n",
      "Iteration 1: log likelihood of observed labels = -36775.13434712\n",
      "Iteration 2: log likelihood of observed labels = -36769.35713564\n",
      "Iteration 3: log likelihood of observed labels = -36763.58603240\n",
      "Iteration 4: log likelihood of observed labels = -36757.82101962\n",
      "Iteration 5: log likelihood of observed labels = -36752.06207964\n",
      "Iteration 6: log likelihood of observed labels = -36746.30919497\n",
      "Iteration 7: log likelihood of observed labels = -36740.56234821\n",
      "Iteration 8: log likelihood of observed labels = -36734.82152213\n",
      "Iteration 9: log likelihood of observed labels = -36729.08669961\n",
      "Iteration 10: log likelihood of observed labels = -36723.35786366\n",
      "Iteration 11: log likelihood of observed labels = -36717.63499744\n",
      "Iteration 12: log likelihood of observed labels = -36711.91808422\n",
      "Iteration 13: log likelihood of observed labels = -36706.20710739\n",
      "Iteration 14: log likelihood of observed labels = -36700.50205049\n",
      "Iteration 15: log likelihood of observed labels = -36694.80289716\n",
      "Iteration 20: log likelihood of observed labels = -36666.39512033\n",
      "Iteration 30: log likelihood of observed labels = -36610.01327118\n",
      "Iteration 40: log likelihood of observed labels = -36554.19728365\n",
      "Iteration 50: log likelihood of observed labels = -36498.93316099\n",
      "Iteration 60: log likelihood of observed labels = -36444.20783914\n",
      "Iteration 70: log likelihood of observed labels = -36390.00909449\n",
      "Iteration 80: log likelihood of observed labels = -36336.32546144\n",
      "Iteration 90: log likelihood of observed labels = -36283.14615871\n",
      "Iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "Iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "Iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "coefficients=logistic_regression(feature_matrix,sentiment,initial_coefficients,step_size,max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=np.dot(feature_matrix,coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result=[]\n",
    "for score in scores:\n",
    "    if score>0:\n",
    "        predict_result.append(+1)\n",
    "    else:\n",
    "        predict_result.append(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: How many reviews were predicted to have positive sentiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25126"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for p in predict_result:\n",
    "    if p == 1:\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result=np.array(predict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_measure(predictions,outcomes):\n",
    "    misclassified=predictions - outcomes\n",
    "    total_points=predictions.shape[0]\n",
    "    n_misclassified=len(misclassified.nonzero()[0])\n",
    "    accuracy = (total_points - n_misclassified)/total_points\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518653904130238"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_measure(predict_result,sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words contribute most to positive and negative sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients=list(coefficients[1:])\n",
    "word_coefficient_tuples=[(word,coefficient) for word,coefficient in zip(important_words,coefficients)]\n",
    "word_coefficient_tuples=sorted(word_coefficient_tuples,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: Which word is not present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.0665460841704577),\n",
       " ('love', 0.06589076292212326),\n",
       " ('easy', 0.06479458680257838),\n",
       " ('little', 0.04543562630842138),\n",
       " ('loves', 0.04497640139490604),\n",
       " ('well', 0.030135001092107067),\n",
       " ('perfect', 0.02973993710496846),\n",
       " ('old', 0.02007754103477538),\n",
       " ('nice', 0.018408707995268992),\n",
       " ('daughter', 0.017703199905701694)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: Which word is not present in the top 10 \"most negative\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('monitor', -0.02448210054589172),\n",
       " ('return', -0.026592778462247283),\n",
       " ('back', -0.027742697230661334),\n",
       " ('get', -0.028711552980192585),\n",
       " ('disappointed', -0.028978976142317068),\n",
       " ('even', -0.030051249236035808),\n",
       " ('work', -0.03306951529475272),\n",
       " ('money', -0.03898203728648711),\n",
       " ('product', -0.04151103339210889),\n",
       " ('would', -0.05386014844520313)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015565696580423508"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
